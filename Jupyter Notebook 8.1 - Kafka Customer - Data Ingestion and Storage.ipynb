{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2556c415",
   "metadata": {},
   "source": [
    "# Kafka Customer - Data Ingestion and Storage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67754416",
   "metadata": {},
   "source": [
    "A notebook that is used on the local machine to connect to the Kafka server and act as the consumer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5ae7116",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a9f8689",
   "metadata": {},
   "source": [
    "##### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9f94328",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-23T16:58:29.429030Z",
     "start_time": "2023-11-23T16:58:27.375054Z"
    }
   },
   "outputs": [],
   "source": [
    "# Libraries in the Consumer Notebook\n",
    "\n",
    "# General\n",
    "import time\n",
    "import os\n",
    "\n",
    "# Data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Data Visualisation\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# SQL\n",
    "import pymysql\n",
    "\n",
    "# Data types\n",
    "import json\n",
    "import pickle\n",
    "import joblib\n",
    "import avro\n",
    "\n",
    "# Avro objects\n",
    "import io\n",
    "import fastavro\n",
    "\n",
    "# Kafka\n",
    "from confluent_kafka import Consumer, KafkaException, KafkaError\n",
    "\n",
    "# Machine Learning Model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4a0504e5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-24T13:26:42.117742Z",
     "start_time": "2023-11-24T13:26:42.110388Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5207f52",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa3a2083",
   "metadata": {},
   "source": [
    "# Data Ingestion and Storage Consumer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24bed175",
   "metadata": {},
   "source": [
    "## Load schema for features and labels. Created in the Producer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8020d3bf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-23T16:58:31.000786Z",
     "start_time": "2023-11-23T16:58:30.990286Z"
    }
   },
   "outputs": [],
   "source": [
    "# ###############################\n",
    "def load_avro_schema_with_fastavro(schema_file_path):\n",
    "    schema = fastavro.schema.load_schema(schema_file_path)\n",
    "    return schema\n",
    "\n",
    "# folder location and file names for the schema files\n",
    "folder_path = r'C:\\Users\\Kolobane\\OneDrive\\CIT MSc Data Science Modules\\_Semester Three - Final Project\\Project Two - Network Project\\Data\\Avro Schema'\n",
    "features_avro_schema_file = \"features_avro_schema.avsc\" \n",
    "label_avro_schema_file = \"label_avro_schema.avsc\"\n",
    "\n",
    "# Call each scehma\n",
    "features_avro_schema = load_avro_schema_with_fastavro(os.path.join(folder_path ,features_avro_schema_file)) \n",
    "label_avro_schema = load_avro_schema_with_fastavro(os.path.join(folder_path, label_avro_schema_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3329f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # features_avro_schema\n",
    "# label_avro_schema "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f45ee23",
   "metadata": {},
   "source": [
    "# Functions to deserialise data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a62b996d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-23T16:58:33.779750Z",
     "start_time": "2023-11-23T16:58:33.758684Z"
    }
   },
   "outputs": [],
   "source": [
    "def deserialise_features_avro_record(avro_bytes, schema):\n",
    "    bytes_reader = io.BytesIO(avro_bytes)\n",
    "    deserialised_data = []\n",
    "    for record in fastavro.reader(bytes_reader, reader_schema=schema):\n",
    "        deserialised_data.append(record)\n",
    "    return deserialised_data\n",
    "\n",
    "def deserialise_label_avro_record(avro_bytes, schema):\n",
    "    bytes_reader = io.BytesIO(avro_bytes)\n",
    "    deserialised_data = []\n",
    "    for record in fastavro.reader(bytes_reader, reader_schema=schema):\n",
    "        deserialised_data.append(record)\n",
    "    return deserialised_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "641718ee",
   "metadata": {},
   "source": [
    "## Consumer to save message to file from the producer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6221da81",
   "metadata": {},
   "source": [
    "**NOTE:** - Update Location of saved files each time for step by step build of project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4d4061fc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-23T19:00:02.261910Z",
     "start_time": "2023-11-23T18:11:48.446518Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0 labels saveed to folder.\n",
      "Batch 0 features saveed to folder.\n",
      "Batch 1 features saveed to folder.\n",
      "Batch 1 labels saveed to folder.\n",
      "Batch 2 labels saveed to folder.\n",
      "Batch 2 features saveed to folder.\n",
      "Batch 3 labels saveed to folder.\n",
      "Batch 3 features saveed to folder.\n",
      "Batch 4 labels saveed to folder.\n",
      "Batch 4 features saveed to folder.\n",
      "Batch 5 labels saveed to folder.\n",
      "Batch 5 features saveed to folder.\n",
      "Batch 6 labels saveed to folder.\n",
      "Batch 6 features saveed to folder.\n",
      "Batch 7 features saveed to folder.\n",
      "Batch 7 labels saveed to folder.\n",
      "Batch 8 features saveed to folder.\n",
      "Batch 8 labels saveed to folder.\n",
      "Batch 9 labels saveed to folder.\n",
      "Batch 9 features saveed to folder.\n",
      "Batch 10 labels saveed to folder.\n",
      "Batch 10 features saveed to folder.\n",
      "Batch 11 labels saveed to folder.\n",
      "Batch 11 features saveed to folder.\n",
      "Batch 12 features saveed to folder.\n",
      "Batch 12 labels saveed to folder.\n",
      "Batch 13 labels saveed to folder.\n",
      "Batch 13 features saveed to folder.\n",
      "Batch 14 labels saveed to folder.\n",
      "Batch 14 features saveed to folder.\n",
      "Batch 15 labels saveed to folder.\n",
      "Batch 15 features saveed to folder.\n",
      "Batch 16 labels saveed to folder.\n",
      "Batch 16 features saveed to folder.\n",
      "Batch 17 labels saveed to folder.\n",
      "Batch 17 features saveed to folder.\n",
      "Batch 18 labels saveed to folder.\n",
      "Batch 18 features saveed to folder.\n",
      "Batch 19 labels saveed to folder.\n",
      "Batch 19 features saveed to folder.\n",
      "Batch 20 labels saveed to folder.\n",
      "Batch 20 features saveed to folder.\n",
      "Batch 21 labels saveed to folder.\n",
      "Batch 21 features saveed to folder.\n",
      "Batch 22 labels saveed to folder.\n",
      "Batch 22 features saveed to folder.\n",
      "Batch 23 labels saveed to folder.\n",
      "Batch 23 features saveed to folder.\n",
      "Batch 24 labels saveed to folder.\n",
      "Batch 24 features saveed to folder.\n",
      "Batch 25 labels saveed to folder.\n",
      "Batch 25 features saveed to folder.\n",
      "Batch 26 labels saveed to folder.\n",
      "Batch 26 features saveed to folder.\n",
      "Batch 27 labels saveed to folder.\n",
      "Batch 27 features saveed to folder.\n",
      "Batch 28 labels saveed to folder.\n",
      "Batch 28 features saveed to folder.\n",
      "Batch 29 labels saveed to folder.\n",
      "Batch 29 features saveed to folder.\n",
      "Batch 30 labels saveed to folder.\n",
      "Batch 30 features saveed to folder.\n",
      "Batch 31 labels saveed to folder.\n",
      "Batch 31 features saveed to folder.\n",
      "Batch 32 labels saveed to folder.\n",
      "Batch 32 features saveed to folder.\n",
      "Batch 33 labels saveed to folder.\n",
      "Batch 33 features saveed to folder.\n",
      "Batch 34 labels saveed to folder.\n",
      "Batch 34 features saveed to folder.\n",
      "Batch 35 labels saveed to folder.\n",
      "Batch 35 features saveed to folder.\n",
      "Batch 36 features saveed to folder.\n",
      "Batch 36 labels saveed to folder.\n",
      "Batch 37 labels saveed to folder.\n",
      "Batch 37 features saveed to folder.\n",
      "Batch 38 labels saveed to folder.\n",
      "Batch 38 features saveed to folder.\n",
      "Batch 39 labels saveed to folder.\n",
      "Batch 39 features saveed to folder.\n",
      "Batch 40 features saveed to folder.\n",
      "Batch 40 labels saveed to folder.\n",
      "Batch 41 features saveed to folder.\n",
      "Batch 41 labels saveed to folder.\n",
      "Batch 42 labels saveed to folder.\n",
      "Batch 42 features saveed to folder.\n",
      "Batch 43 labels saveed to folder.\n",
      "Batch 43 features saveed to folder.\n",
      "Batch 44 labels saveed to folder.\n",
      "Batch 44 features saveed to folder.\n",
      "Batch 45 labels saveed to folder.\n",
      "Batch 45 features saveed to folder.\n",
      "Batch 46 labels saveed to folder.\n",
      "Batch 46 features saveed to folder.\n",
      "Batch 47 labels saveed to folder.\n",
      "Batch 47 features saveed to folder.\n",
      "Batch 48 features saveed to folder.\n",
      "Batch 48 labels saveed to folder.\n",
      "Batch 49 features saveed to folder.\n",
      "Batch 49 labels saveed to folder.\n",
      "Batch 50 labels saveed to folder.\n",
      "Batch 50 features saveed to folder.\n",
      "Batch 51 features saveed to folder.\n",
      "Batch 51 labels saveed to folder.\n",
      "Batch 52 labels saveed to folder.\n",
      "Batch 52 features saveed to folder.\n",
      "Batch 53 labels saveed to folder.\n",
      "Batch 53 features saveed to folder.\n",
      "Batch 54 labels saveed to folder.\n",
      "Batch 54 features saveed to folder.\n",
      "Batch 55 labels saveed to folder.\n",
      "Batch 55 features saveed to folder.\n",
      "Batch 56 labels saveed to folder.\n",
      "Batch 56 features saveed to folder.\n",
      "Batch 57 labels saveed to folder.\n",
      "Batch 57 features saveed to folder.\n",
      "Batch 58 labels saveed to folder.\n",
      "Batch 58 features saveed to folder.\n",
      "Batch 59 labels saveed to folder.\n",
      "Batch 59 features saveed to folder.\n",
      "Batch 60 labels saveed to folder.\n",
      "Batch 60 features saveed to folder.\n",
      "Batch 61 labels saveed to folder.\n",
      "Batch 61 features saveed to folder.\n",
      "Batch 62 features saveed to folder.\n",
      "Batch 62 labels saveed to folder.\n",
      "Batch 63 features saveed to folder.\n",
      "Batch 63 labels saveed to folder.\n",
      "Batch 64 labels saveed to folder.\n",
      "Batch 64 features saveed to folder.\n",
      "Batch 65 labels saveed to folder.\n",
      "Batch 65 features saveed to folder.\n",
      "Batch 66 features saveed to folder.\n",
      "Batch 66 labels saveed to folder.\n",
      "Batch 67 labels saveed to folder.\n",
      "Batch 67 features saveed to folder.\n",
      "Batch 68 labels saveed to folder.\n",
      "Batch 68 features saveed to folder.\n",
      "Batch 69 features saveed to folder.\n",
      "Batch 69 labels saveed to folder.\n",
      "Batch 70 labels saveed to folder.\n",
      "Batch 70 features saveed to folder.\n",
      "Batch 71 features saveed to folder.\n",
      "Batch 71 labels saveed to folder.\n",
      "Batch 72 labels saveed to folder.\n",
      "Batch 72 features saveed to folder.\n",
      "Batch 73 labels saveed to folder.\n",
      "Batch 73 features saveed to folder.\n",
      "Batch 74 labels saveed to folder.\n",
      "Batch 74 features saveed to folder.\n",
      "Batch 75 features saveed to folder.\n",
      "Batch 75 labels saveed to folder.\n",
      "Batch 76 features saveed to folder.\n",
      "Batch 76 labels saveed to folder.\n",
      "Batch 77 labels saveed to folder.\n",
      "Batch 77 features saveed to folder.\n",
      "Batch 78 labels saveed to folder.\n",
      "Batch 78 features saveed to folder.\n",
      "Batch 79 labels saveed to folder.\n",
      "Batch 79 features saveed to folder.\n",
      "Batch 80 features saveed to folder.\n",
      "Batch 80 labels saveed to folder.\n",
      "Batch 81 labels saveed to folder.\n",
      "Batch 81 features saveed to folder.\n",
      "Batch 82 labels saveed to folder.\n",
      "Batch 82 features saveed to folder.\n",
      "Batch 83 features saveed to folder.\n",
      "Batch 83 labels saveed to folder.\n",
      "Batch 84 labels saveed to folder.\n",
      "Batch 84 features saveed to folder.\n",
      "Batch 85 labels saveed to folder.\n",
      "Batch 85 features saveed to folder.\n",
      "Batch 86 labels saveed to folder.\n",
      "Batch 86 features saveed to folder.\n",
      "Batch 87 labels saveed to folder.\n",
      "Batch 87 features saveed to folder.\n",
      "Batch 88 labels saveed to folder.\n",
      "Batch 88 features saveed to folder.\n",
      "Batch 89 labels saveed to folder.\n",
      "Batch 89 features saveed to folder.\n",
      "Batch 90 labels saveed to folder.\n",
      "Batch 90 features saveed to folder.\n",
      "Batch 91 features saveed to folder.\n",
      "Batch 91 labels saveed to folder.\n",
      "Batch 92 labels saveed to folder.\n",
      "Batch 92 features saveed to folder.\n",
      "Batch 93 features saveed to folder.\n",
      "Batch 93 labels saveed to folder.\n",
      "Batch 94 labels saveed to folder.\n",
      "Batch 94 features saveed to folder.\n",
      "Batch 95 labels saveed to folder.\n",
      "Batch 95 features saveed to folder.\n",
      "Batch 96 features saveed to folder.\n",
      "Batch 96 labels saveed to folder.\n",
      "Batch 97 labels saveed to folder.\n",
      "Batch 97 features saveed to folder.\n",
      "Batch 98 labels saveed to folder.\n",
      "Batch 98 features saveed to folder.\n",
      "Batch 99 labels saveed to folder.\n",
      "Batch 99 features saveed to folder.\n",
      "Batch 100 labels saveed to folder.\n",
      "Batch 100 features saveed to folder.\n",
      "Batch 101 labels saveed to folder.\n",
      "Batch 101 features saveed to folder.\n",
      "Batch 102 labels saveed to folder.\n",
      "Batch 102 features saveed to folder.\n",
      "Batch 103 labels saveed to folder.\n",
      "Batch 103 features saveed to folder.\n",
      "Batch 104 labels saveed to folder.\n",
      "Batch 104 features saveed to folder.\n",
      "Batch 105 labels saveed to folder.\n",
      "Batch 105 features saveed to folder.\n",
      "Batch 106 labels saveed to folder.\n",
      "Batch 106 features saveed to folder.\n",
      "Batch 107 labels saveed to folder.\n",
      "Batch 107 features saveed to folder.\n",
      "Batch 108 labels saveed to folder.\n",
      "Batch 108 features saveed to folder.\n",
      "Batch 109 labels saveed to folder.\n",
      "Batch 109 features saveed to folder.\n",
      "Batch 110 labels saveed to folder.\n",
      "Batch 110 features saveed to folder.\n",
      "Batch 111 labels saveed to folder.\n",
      "Batch 111 features saveed to folder.\n",
      "Batch 112 labels saveed to folder.\n",
      "Batch 112 features saveed to folder.\n",
      "Batch 113 labels saveed to folder.\n",
      "Batch 113 features saveed to folder.\n",
      "Batch 114 labels saveed to folder.\n",
      "Batch 114 features saveed to folder.\n",
      "Batch 115 labels saveed to folder.\n",
      "Batch 115 features saveed to folder.\n",
      "Batch 116 labels saveed to folder.\n",
      "Batch 116 features saveed to folder.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 117 labels saveed to folder.\n",
      "Batch 117 features saveed to folder.\n",
      "Batch 118 labels saveed to folder.\n",
      "Batch 118 features saveed to folder.\n",
      "Batch 119 features saveed to folder.\n",
      "Batch 119 labels saveed to folder.\n",
      "Batch 120 labels saveed to folder.\n",
      "Batch 120 features saveed to folder.\n",
      "Batch 121 labels saveed to folder.\n",
      "Batch 121 features saveed to folder.\n",
      "Batch 122 labels saveed to folder.\n",
      "Batch 122 features saveed to folder.\n",
      "Batch 123 labels saveed to folder.\n",
      "Batch 123 features saveed to folder.\n",
      "Batch 124 labels saveed to folder.\n",
      "Batch 124 features saveed to folder.\n",
      "Batch 125 labels saveed to folder.\n",
      "Batch 125 features saveed to folder.\n",
      "Batch 126 features saveed to folder.\n",
      "Batch 126 labels saveed to folder.\n",
      "Batch 127 labels saveed to folder.\n",
      "Batch 127 features saveed to folder.\n",
      "Batch 128 labels saveed to folder.\n",
      "Batch 128 features saveed to folder.\n",
      "Batch 129 labels saveed to folder.\n",
      "Batch 129 features saveed to folder.\n",
      "Batch 130 labels saveed to folder.\n",
      "Batch 130 features saveed to folder.\n",
      "Batch 131 labels saveed to folder.\n",
      "Batch 131 features saveed to folder.\n",
      "Batch 132 labels saveed to folder.\n",
      "Batch 132 features saveed to folder.\n",
      "Batch 133 labels saveed to folder.\n",
      "Batch 133 features saveed to folder.\n",
      "Batch 134 features saveed to folder.\n",
      "Batch 134 labels saveed to folder.\n",
      "Batch 135 features saveed to folder.\n",
      "Batch 135 labels saveed to folder.\n",
      "Batch 136 features saveed to folder.\n",
      "Batch 136 labels saveed to folder.\n",
      "Batch 137 features saveed to folder.\n",
      "Batch 137 labels saveed to folder.\n",
      "Batch 138 labels saveed to folder.\n",
      "Batch 138 features saveed to folder.\n",
      "Batch 139 features saveed to folder.\n",
      "Batch 139 labels saveed to folder.\n",
      "Batch 140 features saveed to folder.\n",
      "Batch 140 labels saveed to folder.\n",
      "Batch 141 features saveed to folder.\n",
      "Batch 141 labels saveed to folder.\n",
      "Batch 142 features saveed to folder.\n",
      "Batch 142 labels saveed to folder.\n",
      "Batch 143 labels saveed to folder.\n",
      "Batch 143 features saveed to folder.\n",
      "Batch 144 labels saveed to folder.\n",
      "Batch 144 features saveed to folder.\n",
      "Batch 145 labels saveed to folder.\n",
      "Batch 145 features saveed to folder.\n",
      "Batch 146 labels saveed to folder.\n",
      "Batch 146 features saveed to folder.\n",
      "Batch 147 features saveed to folder.\n",
      "Batch 147 labels saveed to folder.\n",
      "Batch 148 labels saveed to folder.\n",
      "Batch 148 features saveed to folder.\n",
      "Batch 149 labels saveed to folder.\n",
      "Batch 149 features saveed to folder.\n",
      "Batch 150 labels saveed to folder.\n",
      "Batch 150 features saveed to folder.\n",
      "Batch 151 labels saveed to folder.\n",
      "Batch 151 features saveed to folder.\n",
      "Batch 152 labels saveed to folder.\n",
      "Batch 152 features saveed to folder.\n",
      "Batch 153 labels saveed to folder.\n",
      "Batch 153 features saveed to folder.\n",
      "Batch 154 labels saveed to folder.\n",
      "Batch 154 features saveed to folder.\n",
      "Batch 155 labels saveed to folder.\n",
      "Batch 155 features saveed to folder.\n",
      "Batch 156 features saveed to folder.\n",
      "Batch 156 labels saveed to folder.\n",
      "Batch 157 features saveed to folder.\n",
      "Batch 157 labels saveed to folder.\n",
      "Batch 158 features saveed to folder.\n",
      "Batch 158 labels saveed to folder.\n",
      "Batch 159 labels saveed to folder.\n",
      "Batch 159 features saveed to folder.\n",
      "Batch 160 labels saveed to folder.\n",
      "Batch 160 features saveed to folder.\n",
      "Batch 161 labels saveed to folder.\n",
      "Batch 161 features saveed to folder.\n",
      "Batch 162 labels saveed to folder.\n",
      "Batch 162 features saveed to folder.\n",
      "Batch 163 labels saveed to folder.\n",
      "Batch 163 features saveed to folder.\n",
      "Batch 164 labels saveed to folder.\n",
      "Batch 164 features saveed to folder.\n",
      "Batch 165 labels saveed to folder.\n",
      "Batch 165 features saveed to folder.\n",
      "Batch 166 labels saveed to folder.\n",
      "Batch 166 features saveed to folder.\n",
      "Batch 167 labels saveed to folder.\n",
      "Batch 167 features saveed to folder.\n",
      "Batch 168 labels saveed to folder.\n",
      "Batch 168 features saveed to folder.\n",
      "Batch 169 labels saveed to folder.\n",
      "Batch 169 features saveed to folder.\n",
      "Batch 170 labels saveed to folder.\n",
      "Batch 170 features saveed to folder.\n",
      "Batch 171 labels saveed to folder.\n",
      "Batch 171 features saveed to folder.\n",
      "Batch 172 labels saveed to folder.\n",
      "Batch 172 features saveed to folder.\n",
      "Batch 173 labels saveed to folder.\n",
      "Batch 173 features saveed to folder.\n",
      "Batch 174 features saveed to folder.\n",
      "Batch 174 labels saveed to folder.\n",
      "Batch 175 labels saveed to folder.\n",
      "Batch 175 features saveed to folder.\n",
      "Batch 176 labels saveed to folder.\n",
      "Batch 176 features saveed to folder.\n",
      "Batch 177 labels saveed to folder.\n",
      "Batch 177 features saveed to folder.\n",
      "Batch 178 labels saveed to folder.\n",
      "Batch 178 features saveed to folder.\n",
      "Batch 179 labels saveed to folder.\n",
      "Batch 179 features saveed to folder.\n",
      "Batch 180 labels saveed to folder.\n",
      "Batch 180 features saveed to folder.\n",
      "Batch 181 labels saveed to folder.\n",
      "Batch 181 features saveed to folder.\n",
      "Batch 182 labels saveed to folder.\n",
      "Batch 182 features saveed to folder.\n",
      "Batch 183 labels saveed to folder.\n",
      "Batch 183 features saveed to folder.\n",
      "Batch 184 labels saveed to folder.\n",
      "Batch 184 features saveed to folder.\n",
      "Batch 185 labels saveed to folder.\n",
      "Batch 185 features saveed to folder.\n",
      "Batch 186 features saveed to folder.\n",
      "Batch 186 labels saveed to folder.\n",
      "Batch 187 labels saveed to folder.\n",
      "Batch 187 features saveed to folder.\n",
      "Batch 188 labels saveed to folder.\n",
      "Batch 188 features saveed to folder.\n",
      "Batch 189 labels saveed to folder.\n",
      "Batch 189 features saveed to folder.\n",
      "Batch 190 labels saveed to folder.\n",
      "Batch 190 features saveed to folder.\n",
      "Batch 191 labels saveed to folder.\n",
      "Batch 191 features saveed to folder.\n",
      "Batch 192 labels saveed to folder.\n",
      "Batch 192 features saveed to folder.\n",
      "Batch 193 labels saveed to folder.\n",
      "Batch 193 features saveed to folder.\n",
      "Batch 194 labels saveed to folder.\n",
      "Batch 194 features saveed to folder.\n",
      "Batch 195 features saveed to folder.\n",
      "Batch 195 labels saveed to folder.\n",
      "Batch 196 labels saveed to folder.\n",
      "Batch 196 features saveed to folder.\n",
      "Batch 197 labels saveed to folder.\n",
      "Batch 197 features saveed to folder.\n",
      "Batch 198 labels saveed to folder.\n",
      "Batch 198 features saveed to folder.\n",
      "Batch 199 labels saveed to folder.\n",
      "Batch 199 features saveed to folder.\n",
      "Batch 200 labels saveed to folder.\n",
      "Batch 200 features saveed to folder.\n",
      "Batch 201 labels saveed to folder.\n",
      "Batch 201 features saveed to folder.\n",
      "Batch 202 labels saveed to folder.\n",
      "Batch 202 features saveed to folder.\n",
      "Batch 203 labels saveed to folder.\n",
      "Batch 203 features saveed to folder.\n",
      "Batch 204 features saveed to folder.\n",
      "Batch 204 labels saveed to folder.\n",
      "Batch 205 features saveed to folder.\n",
      "Batch 205 labels saveed to folder.\n",
      "Batch 206 labels saveed to folder.\n",
      "Batch 206 features saveed to folder.\n",
      "Batch 207 features saveed to folder.\n",
      "Batch 207 labels saveed to folder.\n",
      "Batch 208 features saveed to folder.\n",
      "Batch 208 labels saveed to folder.\n",
      "Batch 209 labels saveed to folder.\n",
      "Batch 209 features saveed to folder.\n",
      "Batch 210 labels saveed to folder.\n",
      "Batch 210 features saveed to folder.\n",
      "Batch 211 labels saveed to folder.\n",
      "Batch 211 features saveed to folder.\n",
      "Batch 212 labels saveed to folder.\n",
      "Batch 212 features saveed to folder.\n",
      "Batch 213 labels saveed to folder.\n",
      "Batch 213 features saveed to folder.\n",
      "Batch 214 labels saveed to folder.\n",
      "Batch 214 features saveed to folder.\n",
      "Batch 215 labels saveed to folder.\n",
      "Batch 215 features saveed to folder.\n",
      "Batch 216 features saveed to folder.\n",
      "Batch 216 labels saveed to folder.\n",
      "Batch 217 features saveed to folder.\n",
      "Batch 217 labels saveed to folder.\n",
      "Batch 218 labels saveed to folder.\n",
      "Batch 218 features saveed to folder.\n",
      "Batch 219 labels saveed to folder.\n",
      "Batch 219 features saveed to folder.\n",
      "Batch 220 labels saveed to folder.\n",
      "Batch 220 features saveed to folder.\n",
      "Batch 221 labels saveed to folder.\n",
      "Batch 221 features saveed to folder.\n",
      "Batch 222 labels saveed to folder.\n",
      "Batch 222 features saveed to folder.\n",
      "Batch 223 labels saveed to folder.\n",
      "Batch 223 features saveed to folder.\n",
      "Batch 224 labels saveed to folder.\n",
      "Batch 224 features saveed to folder.\n",
      "Batch 225 labels saveed to folder.\n",
      "Batch 225 features saveed to folder.\n",
      "Batch 226 labels saveed to folder.\n",
      "Batch 226 features saveed to folder.\n",
      "Batch 227 labels saveed to folder.\n",
      "Batch 227 features saveed to folder.\n",
      "Batch 228 labels saveed to folder.\n",
      "Batch 228 features saveed to folder.\n",
      "Batch 229 labels saveed to folder.\n",
      "Batch 229 features saveed to folder.\n",
      "Batch 230 labels saveed to folder.\n",
      "Batch 230 features saveed to folder.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 231 features saveed to folder.\n",
      "Batch 231 labels saveed to folder.\n",
      "Batch 232 labels saveed to folder.\n",
      "Batch 232 features saveed to folder.\n",
      "Batch 233 labels saveed to folder.\n",
      "Batch 233 features saveed to folder.\n",
      "Batch 234 labels saveed to folder.\n",
      "Batch 234 features saveed to folder.\n",
      "Batch 235 features saveed to folder.\n",
      "Batch 235 labels saveed to folder.\n",
      "Batch 236 features saveed to folder.\n",
      "Batch 236 labels saveed to folder.\n",
      "Batch 237 features saveed to folder.\n",
      "Batch 237 labels saveed to folder.\n",
      "Batch 238 labels saveed to folder.\n",
      "Batch 238 features saveed to folder.\n",
      "Batch 239 labels saveed to folder.\n",
      "Batch 239 features saveed to folder.\n",
      "Batch 240 labels saveed to folder.\n",
      "Batch 240 features saveed to folder.\n",
      "Batch 241 labels saveed to folder.\n",
      "Batch 241 features saveed to folder.\n",
      "Batch 242 labels saveed to folder.\n",
      "Batch 242 features saveed to folder.\n",
      "Batch 243 labels saveed to folder.\n",
      "Batch 243 features saveed to folder.\n",
      "Batch 244 labels saveed to folder.\n",
      "Batch 244 features saveed to folder.\n",
      "Batch 245 labels saveed to folder.\n",
      "Batch 245 features saveed to folder.\n",
      "Batch 246 features saveed to folder.\n",
      "Batch 246 labels saveed to folder.\n",
      "Batch 247 features saveed to folder.\n",
      "Batch 247 labels saveed to folder.\n",
      "Batch 248 features saveed to folder.\n",
      "Batch 248 labels saveed to folder.\n",
      "Batch 249 features saveed to folder.\n",
      "Batch 249 labels saveed to folder.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 26\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m: \n\u001b[0;32m     25\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m---> 26\u001b[0m         msg \u001b[38;5;241m=\u001b[39m \u001b[43mconsumer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpoll\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1.0\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# poll the first topic\u001b[39;00m\n\u001b[0;32m     28\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m msg \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     29\u001b[0m             \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "############################################################\n",
    "# Set up the Kafka configuration\n",
    "############################################################\n",
    "# Kafka configuration\n",
    "conf = {'bootstrap.servers': 'localhost:9092', # Local kafka server address (local machine)\n",
    "       'group.id':'jupyter-consumer-group',\n",
    "       'auto.offset.reset': 'earliest'} # Start from the beginning of the topic. \n",
    "\n",
    "# Create Kafka Consumer instance\n",
    "consumer = Consumer(conf)\n",
    "\n",
    "# Subscribe to the topics\n",
    "consumer.subscribe([\"batch-network-data\", \"test-batch-labels\"]) # consumer needs to listen to both topics.\n",
    "\n",
    "############################################################\n",
    "# Save batches to folder\n",
    "############################################################\n",
    "# Location to store the producer messages.\n",
    "folder_path =  r\"C:\\Users\\Kolobane\\OneDrive\\CIT MSc Data Science Modules\\_Semester Three - Final Project\\Project Two - Network Project\\Data\\Consumer Data\\Avro Batches 2500 avro files\"\n",
    "\n",
    "############################################################\n",
    "# Start Consumer polling\n",
    "############################################################\n",
    "try: \n",
    "    while True:\n",
    "        msg = consumer.poll(1.0) # poll the first topic\n",
    "        \n",
    "        if msg is None:\n",
    "            continue\n",
    "        if msg.error():\n",
    "            print(f\"Consumer error: {msg.error()}\")\n",
    "            continue   \n",
    "        \n",
    "        ############################################################\n",
    "        # Check Topics - this is kept seperate for the next models.\n",
    "        ############################################################\n",
    "    \n",
    "        #######################\n",
    "        # Extract the batch number and avro bytes\n",
    "        batch_number = int(msg.key())\n",
    "        avro_bytes = msg.value()\n",
    "    \n",
    "        #######################\n",
    "        # Check if topics are from \"batch-network-data\" or \"label-batch-labels\"\n",
    "        if msg.topic() == \"batch-network-data\":\n",
    "            file_path = os.path.join(folder_path, f\"features_batch_{batch_number}.avro\")\n",
    "            data_type = \"features\"\n",
    "        if msg.topic() == \"test-batch-labels\":\n",
    "            file_path = os.path.join(folder_path, f\"label_batch_{batch_number}.avro\")\n",
    "            data_type = \"labels\"\n",
    "            \n",
    "        #######################\n",
    "        # Write to file\n",
    "        with open(file_path, \"wb\") as file:\n",
    "            file.write(avro_bytes)\n",
    "            \n",
    "        #######################\n",
    "        # Print batch confirmation messagge \n",
    "        print(f\"Batch {batch_number} {data_type} saveed to folder.\")\n",
    "        \n",
    "\n",
    "############################################################\n",
    "# Error handling and logging\n",
    "############################################################             \n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")   \n",
    "    \n",
    "############################################################\n",
    "# Clean up and close\n",
    "# ############################################################        \n",
    "finally:\n",
    "    consumer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde04b53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8a997c39",
   "metadata": {},
   "source": [
    "Previously Data Ingestion \n",
    "  - 10% data:\n",
    "      - 5 Batches - DONE\n",
    "      - 100 Batches - DONE\n",
    "      - 250 Batches - DONE\n",
    "  - Full Files\n",
    "      - ??? Batches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "effa3c5e",
   "metadata": {},
   "source": [
    "**Conclusion**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "634be9be",
   "metadata": {},
   "source": [
    "Working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97174631",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "70b2e39c",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bef748c0",
   "metadata": {},
   "source": [
    "# Older Code - Used for testing various options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab60ec7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4f9af247",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab21475e",
   "metadata": {},
   "source": [
    "# Basic Consumer test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f428ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Kafka configuration\n",
    "# conf = {'bootstrap.servers': 'localhost:9092', # Local kafka server address (local machine)\n",
    "#        'group.id':'jupyter-consumer-group',\n",
    "#        'auto.offset.reset': 'earliest'} # Start from the beginning of the topic. \n",
    "\n",
    "# # Create a consumer instance\n",
    "# consumer = Consumer(conf)\n",
    "\n",
    "# # Subscribe to the topic\n",
    "# consumer.subscribe(['network-data-events'])\n",
    "\n",
    "# # Use a try, except, finally to allow kafka consumer to shut down gracefully.\n",
    "# # Try, continuously polls for new messages. Start the porducer to get a messages sent to the consumer\n",
    "# # except, lets you handle errors, \n",
    "# # Finally, lets you execte code. Lets the cosumer code be closed.\n",
    "\n",
    "# try:\n",
    "#     # Code block to poll messages from the producer\n",
    "#     while True:\n",
    "#         msg = consumer.poll(timeout=1.0)\n",
    "#         if msg is None: continue\n",
    "#         if msg.error():\n",
    "#             if msg.error().code() == KafkaError._PARTITION_EOF:\n",
    "#                 # End of partition event\n",
    "#                 print(f'{msg.topic()}[{msg.partition()}] reached end at offset {msg.offset()}')\n",
    "#             elif msg.error():\n",
    "#                 raise KafkaException(msg.error())\n",
    "#         else:\n",
    "#             print(f'Recieved message: {msg.value().decode(\"utf-8\")}')\n",
    "# except KeybaordInterrupt:\n",
    "#     pass\n",
    "# finally:\n",
    "#     # Closes the connection\n",
    "#     consumer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33bf224e",
   "metadata": {},
   "source": [
    "Start the consumer first to be listening for a producer message."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c74199ae",
   "metadata": {},
   "source": [
    "### SQL connection - NOT USED IN THIS CONSUMER NOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4812b293",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T22:28:30.270981Z",
     "start_time": "2023-11-21T22:28:30.257660Z"
    }
   },
   "outputs": [],
   "source": [
    "# # Function to connect to MYSQL connection\n",
    "# def mysql_connection():\n",
    "#     return pymysql.connect(host='localhost',\n",
    "#                             user='root',\n",
    "#                             password='root',\n",
    "#                             db='mtu_capstone_db')            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add1c4a4",
   "metadata": {},
   "source": [
    "### Save Model - - Some models are very large so they are not saved. NOT USED NOW."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb98644e",
   "metadata": {},
   "source": [
    "Models are too large to save, they will be 600mb plus times 50. I don't have the resources for that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1890bfb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T22:28:30.333842Z",
     "start_time": "2023-11-21T22:28:30.318772Z"
    }
   },
   "outputs": [],
   "source": [
    "# def save_model(model, filename):\n",
    "#     model_path = os.path.join('C:\\\\Users\\\\Kolobane\\\\OneDrive\\\\CIT MSc Data Science Modules\\\\_Semester Three - Final Project\\\\Project Two - Network Project\\\\ML Models\\\\Random Forest Real Time Models', filename)\n",
    "#     with open(filename, 'wb') as file:\n",
    "#         pickle.dump(model, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b52eee6e",
   "metadata": {},
   "source": [
    "### Different attemps to serialise data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f550ac3",
   "metadata": {},
   "source": [
    "##### Attempt 1. Didnt work. Match error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2dfc710",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T22:28:30.349634Z",
     "start_time": "2023-11-21T22:28:30.334893Z"
    }
   },
   "outputs": [],
   "source": [
    "# # Take the avro objects from the producer and with the schema, remove the data for use.\n",
    "# def deserialise_avro_record(avro_bytes, avro_schema):\n",
    "#     # Create a datum reader using the schema avro\n",
    "#     reader = DatumReader(avro_schema)\n",
    "    \n",
    "#     # Create a a Binary Decoder with avro bytes\n",
    "#     decoder = BinaryDecoder(io.BytesIO(avro_bytes))\n",
    "    \n",
    "#     return reader.read(decoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bcf7e78",
   "metadata": {},
   "source": [
    "##### Attempt 2: Create two functions, by listing out the featues in the DatumReader did not work. Deleted code "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96035188",
   "metadata": {},
   "source": [
    "###### Attempt 3: Getting a \"Received message from topic: batch-network-data, key: b'0'. Error: unhashable type: 'RecordSchema'\" error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1784252",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T22:28:30.365497Z",
     "start_time": "2023-11-21T22:28:30.350640Z"
    }
   },
   "outputs": [],
   "source": [
    "# def deserialise_features_avro_record(avro_bytes, features_avro_schema):\n",
    "#     # Create a by bytesIO steam from the avro bytes\n",
    "#     bytes_reader = io.BytesIO(avro_bytes)\n",
    "    \n",
    "#     # deserailise the data using the schema\n",
    "#     features_data = schemaless_reader(bytes_reader, features_avro_schema)\n",
    "    \n",
    "#     return features_data\n",
    "\n",
    "# def deserialise_label_avro_record(avro_bytes, label_avro_schema):\n",
    "#     # Create a by bytesIO steam from the avro bytes\n",
    "#     bytes_reader = io.BytesIO(avro_bytes)\n",
    "    \n",
    "#     # deserailise the data using the schema\n",
    "#     label_data = schemaless_reader(bytes_reader, label_avro_schema)\n",
    "    \n",
    "#     return label_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf3e77c9",
   "metadata": {},
   "source": [
    "##### Attempt 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc81656",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-22T12:24:34.614949Z",
     "start_time": "2023-11-22T12:24:34.602430Z"
    }
   },
   "outputs": [],
   "source": [
    "# def deserialise_features_avro_record(avro_bytes, schema):\n",
    "#     bytes_reader = io.BytesIO(avro_bytes)\n",
    "#     deserialised_data = []\n",
    "#     for record in fastavro.reader(bytes_reader, reader_schema=schema):\n",
    "#         deserialised_data.append(record)\n",
    "#     return deserialised_data\n",
    "\n",
    "# def deserialise_label_avro_record(avro_bytes, schema):\n",
    "#     bytes_reader = io.BytesIO(avro_bytes)\n",
    "#     deserialised_data = []\n",
    "#     for record in fastavro.reader(bytes_reader, reader_schema=schema):\n",
    "#         deserialised_data.append(record)\n",
    "#     return deserialised_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cac3894f",
   "metadata": {},
   "source": [
    "### Run Consumer 1: Random Forest Basic Model - Work in Progress - NOT USED."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e170086",
   "metadata": {},
   "source": [
    "Set up consumer to listen for the batches sent from the producer. Loads in baseline model, tests the batches, outputs results to database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe15a65",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T22:28:30.397249Z",
     "start_time": "2023-11-21T22:28:30.382717Z"
    }
   },
   "outputs": [],
   "source": [
    "# ############################################################\n",
    "# # Set up the Kafka configuration\n",
    "# ############################################################\n",
    "# # Kafka configuration\n",
    "# conf = {'bootstrap.servers': 'localhost:9092', # Local kafka server address (local machine)\n",
    "#        'group.id':'jupyter-consumer-group',\n",
    "#        'auto.offset.reset': 'earliest'} # Start from the beginning of the topic. \n",
    "\n",
    "# # Create Kafka Consumer instance\n",
    "# consumer = Consumer(conf)\n",
    "\n",
    "# # Subscribe to the topics\n",
    "# consumer.subscribe([\"batch-network-data\", \"test-batch-labels\"]) # consumer needs to listen to both topics.\n",
    "\n",
    "# ############################################################\n",
    "# # Load the baseline model: Random Forest\n",
    "# ############################################################\n",
    "# # # Model Location\n",
    "# # model_path = r\"C:\\Users\\Kolobane\\OneDrive\\CIT MSc Data Science Modules\\_Semester Three - Final Project\\Project Two - Network Project\\ML Models\\rf_model_baseline_basic.joblib\"\n",
    "\n",
    "# # # Load the previous pre-trained baseline model.\n",
    "# # model = joblib.load(model_path)\n",
    "\n",
    "# ############################################################\n",
    "# # Random Forest model parameters\n",
    "# ############################################################\n",
    "# # # For each model I will use the same parameters as I used in the previous models. For RF basic model, thats n_estimators=100\n",
    "# # new_model_hyperparameters = {\n",
    "# #     'n_estimators': 100\n",
    "# # }\n",
    "\n",
    "# ############################################################\n",
    "# # Initialize dictionaries for storing batch data\n",
    "# ############################################################\n",
    "# batch_features = {}\n",
    "# batch_labels = {}\n",
    "\n",
    "# ############################################################\n",
    "# # Start Consumer polling\n",
    "# ############################################################\n",
    "# try: \n",
    "#     while True:\n",
    "#         msg = consumer.poll(1.0) # poll the first topic\n",
    "        \n",
    "#         if msg is None:\n",
    "#             continue\n",
    "#         if msg.error():\n",
    "#             print(f\"Consumer error: {msg.error()}\")\n",
    "#             continue   \n",
    "    \n",
    "#         ############################################################\n",
    "#         # Check Topics - this is kept seperate for the next models.\n",
    "#         ############################################################\n",
    "    \n",
    "#         #######################\n",
    "#         # Check if topics are from \"batch-network-data\"\n",
    "#         if msg.topic() == \"batch-network-data\":\n",
    "#             batch_number = int(msg.key()) # get the batch number\n",
    "#             avro_bytes = msg.value()\n",
    "            \n",
    "#             # Deserilise the avro data with the label_avro_schema loaded above\n",
    "#             avro_data = deserialize_avro_record(avro_bytes, features_avro_schema )\n",
    "#             batch_features[batch_number] = avro_data\n",
    "            \n",
    "    \n",
    "#         #######################\n",
    "#         # Check if topics are from \"test-batch-labels\"\n",
    "#         if msg.topic() == \"test-batch-labels\":\n",
    "#             batch_number = int(msg.key())\n",
    "#             avro_bytes = msg.value()\n",
    "            \n",
    "#             # Deserilise the avro data with the features_avro_schema loaded above\n",
    "#             avro_data = deserialize_avro_record(avro_bytes,label_avro_schema)\n",
    "#             batch_features[batch_number] = avro_data\n",
    "            \n",
    "\n",
    "#         ############################################################\n",
    "#         # Predict Using Baseline Models\n",
    "#         ############################################################\n",
    "    \n",
    "# #         #######################\n",
    "# #         # Use baseline model to make predictions with current batch\n",
    "# #         if batch_number in batch_features and batch_number in batch_labels:\n",
    "# #             batch_features_data = batch_features[batch_number]\n",
    "# #             batch_labels_data = batch_labels[batch_number]\n",
    "            \n",
    "# #             # Make predictions using the baseline model\n",
    "# #             baseline_predictions = model.predict(preprocessed_data)\n",
    "        \n",
    "# #         else:\n",
    "# #             print(\"Batch features or labels are missing for batch number:\", batch_number)\n",
    "        \n",
    "#         ############################################################\n",
    "#         # Combine Features and Labels\n",
    "#         ############################################################\n",
    "        \n",
    "# #         #######################\n",
    "# #         # Combine Features and the labels.\n",
    "# #         if batch_features_data and batch_labels_data:\n",
    "# #             combined_data = {\n",
    "# #                 \"features\": batch_features_data,\n",
    "# #                 \"labels\": batch_labels_data\n",
    "# #             }\n",
    "# #         else:\n",
    "# #             print(\"Batch features or labels are missing for batch number:\", batch_number)\n",
    "        \n",
    "#         ############################################################\n",
    "#         # Evaluate Predictions\n",
    "#         ############################################################\n",
    "        \n",
    "# #         #######################\n",
    "# #         ## Compare the baseline model with the actual labels.\n",
    "# #         if batch_number in baseline_predictios and batch_number in batch_labels:\n",
    "# #             baseline_predictions = baseline_predictions_dict[batch_number]\n",
    "# #             actual_labels = batch_labels[batch_number]\n",
    "            \n",
    "# #             if baseline_predictions and actual_labels:\n",
    "                \n",
    "# #                 # Metrics\n",
    "# #                 accuracy_value = accuracy_score(actual_labels, baseline_predictions)\n",
    "# #                 precision_value = precision_score(actual_labels, baseline_predictions)\n",
    "# #                 recall_value = recall_score(actual_labels, baseline_predictions)\n",
    "# #                 f1_score_value = f1_score(actual_labels, baseline_predictions)\n",
    "# #                 auc_score = roc_auc_score(actual_labels, baseline_predictions)\n",
    "                \n",
    "# #                 # Confusion matrix\n",
    "# #                 confusion_matrix_result = confusion_matrix(actual_labels, baseline_predictions)\n",
    "# #                 confusion_matrix = json.dumps(confusion_matrix, matrix_result.tolist())\n",
    "                \n",
    "# #                 # feature Importance\n",
    "# #                 feature_importance_results = model.feature_importances_\n",
    "# #                 feature_importance = json.dumps(feature_importance_results)           \n",
    "                \n",
    "# #             else:\n",
    "# #                 print(\"Batch data is empty for batch_number:\", batch_number)\n",
    "        \n",
    "# #         else:\n",
    "# #             print(\"Batch predictions or labels missing in batch_number:\", batch_number)\n",
    "        \n",
    "        \n",
    "# #         ############################################################\n",
    "# #         # Retrain the baseline model to get the next baseline model.\n",
    "# #         ############################################################\n",
    "        \n",
    "# #         #######################\n",
    "# #         ## retain model to get new baseline model\n",
    "# #         retrain_start_time = time.time()\n",
    "        \n",
    "# #         # Create a new baseline model with the same hyperparameters\n",
    "# #         new_baseline_model = RandomForestClassifier(**new_model_hyperparameters)\n",
    "        \n",
    "# #         # Retrain the baseline model wiht the batch data\n",
    "# #         new_baseline_model.fit(batch_features_data, batch_labels_data)\n",
    "        \n",
    "# #         # Stop the timer\n",
    "# #         retrain_end_time =  time.time()\n",
    "        \n",
    "# #         #######################\n",
    "# #         # save date\n",
    "# #         model_training_time_seconds = retrain_end_time -retrain_start_time\n",
    "        \n",
    "# #         # save the new model parameters # although I have decided to use the same.\n",
    "# #         new_model_parameters_results = new_baseline_model.get_params()\n",
    "# #         new_model_parameters_results_tolist = new_model_parameters_results.tolist()\n",
    "# #         new_model_parameters = json.dumps(new_model_parameters_results_tolist)\n",
    "        \n",
    "# #         ############################################################\n",
    "# #         # Send values to database\n",
    "# #         ############################################################\n",
    "        \n",
    "# #         #######################\n",
    "# #         ## connect to the database\n",
    "# #         conn = mysql_connection()        \n",
    "# #         cursor = conn.cursor()\n",
    "        \n",
    "# #         #######################\n",
    "# #         ## Create SQL Query\n",
    "# #         insert_query = \"\"\"\n",
    "# #             INSERT INTO rf_basic_rt_model_results(\n",
    "# #                 batch_number, model_name, timestamp, accuracy_value,\n",
    "# #                 precision_value, recall_value, f1_value, auc_score,\n",
    "# #                 confusion_matrix, feature_importance, testing_time_seconds,\n",
    "# #                 model_training_time_seconds, model_parameters\n",
    "# #             )\n",
    "# #             VALUES (%s, %s, NOW(), %s, %s, %s, %s, %s, %s, %s, %s, %s, %s ) \"\"\"\n",
    "\n",
    "# #         # Values to be insert#\n",
    "# #         values =  (\n",
    "# #             batch_number, model_name, accuracy_value,\n",
    "# #             precision_value, recall_value, f1_value, auc_score,\n",
    "# #             confusion_matrix_json, feature_importance_json, testing_time_seconds,\n",
    "# #             retraining_time_seconds, new_model_parameters_json\n",
    "# #         )\n",
    "\n",
    "# #         # Execute the insert query that is defind above\n",
    "# #         cursor.execute(insert_query, values)\n",
    "        \n",
    "# #         # Commit the changes to the database\n",
    "# #         conn.commit()\n",
    "        \n",
    "# #         print(f\"Batch {batch_number} values inserted successfully into the database.\")\n",
    "       \n",
    "              \n",
    "# ############################################################\n",
    "# # Error handling and logging\n",
    "# ############################################################             \n",
    "# except Exception as e:\n",
    "#     print(f\"Error: {e}\")\n",
    "#     if \"conn\" in locals() or \"conn\" in globals():    \n",
    "#         conn.rollback()\n",
    "    \n",
    "# ############################################################\n",
    "# # Clean up and close\n",
    "# ############################################################        \n",
    "# finally:\n",
    "#     # Good practices to reduce issues by cleaning up and closing connections\n",
    "              \n",
    "#     if \"conn\" in locals() or \"conn\" in globals():    \n",
    "#         conn.rollback()\n",
    "#         conn.close()\n",
    "        \n",
    "#     if \"cursor\" in locals() or \"conn\" in globals():   \n",
    "#         cursor.close()\n",
    "    \n",
    "#     consumer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "662f0b37",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (bscapstone)",
   "language": "python",
   "name": "bscapstone"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "333.767px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
